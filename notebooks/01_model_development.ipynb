{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dockerized ML API — Model Development Notebook\n",
    "\n",
    "**Author:** Mike Ichikawa  \n",
    "**Date:** January 2026\n",
    "\n",
    "This notebook walks through the model development process for the anomaly detection ensemble:\n",
    "exploring synthetic sensor data, comparing detector behaviors, and evaluating the ensemble.\n",
    "The final model is serialized and served via FastAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from model.train import generate_data, ensemble_predict, N_FEATURES\n",
    "\n",
    "plt.rcParams.update({'figure.facecolor': 'white', 'axes.grid': True, 'grid.alpha': 0.3})\n",
    "print(f'N_FEATURES = {N_FEATURES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic Data Exploration\n",
    "\n",
    "We generate 10,000 observations: 9,500 normal sensor readings and 500 anomalies (5% contamination).\n",
    "Three types of anomalies are injected: extreme spikes, correlation breaks, and cluster drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_data(n_samples=10000, contamination=0.05)\n",
    "\n",
    "print(f'Total samples: {len(X):,}')\n",
    "print(f'Normal: {(y==0).sum():,} ({(y==0).mean():.1%})')\n",
    "print(f'Anomaly: {(y==1).sum():,} ({(y==1).mean():.1%})')\n",
    "print(f'Feature shape: {X.shape}')\n",
    "\n",
    "# PCA to visualize 8D data in 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('Synthetic Sensor Data — 2D PCA Projection')\n",
    "\n",
    "# All data\n",
    "ax = axes[0]\n",
    "scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y, cmap='RdYlGn_r',\n",
    "                     alpha=0.4, s=8)\n",
    "plt.colorbar(scatter, ax=ax, label='0=normal, 1=anomaly')\n",
    "ax.set_title('Full Dataset (PCA)')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "\n",
    "# Zoom to anomalies only\n",
    "ax = axes[1]\n",
    "ax.scatter(X_2d[y==0, 0], X_2d[y==0, 1], c='#2C7BB6', alpha=0.2, s=5, label='Normal')\n",
    "ax.scatter(X_2d[y==1, 0], X_2d[y==1, 1], c='#D7191C', alpha=0.7, s=20, label='Anomaly', zorder=5)\n",
    "ax.set_title('Anomalies Highlighted')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../model/artifacts/nb_data_pca.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Explained variance ratio: PC1={pca.explained_variance_ratio_[0]:.3f}, PC2={pca.explained_variance_ratio_[1]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual Detector Comparison\n",
    "\n",
    "Let's see how each detector performs independently before combining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:8000], X[8000:]\n",
    "y_train, y_test = y[:8000], y[8000:]\n",
    "\n",
    "# Train detectors\n",
    "iforest = IsolationForest(n_estimators=200, contamination=0.05, random_state=42, n_jobs=-1)\n",
    "iforest.fit(X_train)\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05, novelty=True, n_jobs=-1)\n",
    "lof.fit(X_train)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Individual predictions\n",
    "if_pred  = (iforest.predict(X_test) == -1).astype(int)\n",
    "lof_pred = (lof.predict(X_test) == -1).astype(int)\n",
    "z_pred   = (np.abs(scaler.transform(X_test)).max(axis=1) > 3.0).astype(int)\n",
    "ens_pred = ((if_pred + lof_pred + z_pred) >= 2).astype(int)\n",
    "\n",
    "print('Individual Detector Performance:')\n",
    "print('='*60)\n",
    "for name, pred in [('Isolation Forest', if_pred), ('LOF', lof_pred),\n",
    "                    ('Z-score', z_pred), ('Ensemble (≥2 votes)', ens_pred)]:\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    report = classification_report(y_test, pred, target_names=['normal','anomaly'],\n",
    "                                   output_dict=True)\n",
    "    p = report['anomaly']['precision']\n",
    "    r = report['anomaly']['recall']\n",
    "    print(f'{name:<25} F1={f1:.3f}  Prec={p:.3f}  Recall={r:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score distributions: anomaly vs normal\n",
    "if_scores_normal  = iforest.score_samples(X_test[y_test==0])\n",
    "if_scores_anomaly = iforest.score_samples(X_test[y_test==1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(if_scores_normal, bins=40, alpha=0.6, color='#2C7BB6',\n",
    "        label=f'Normal (n={len(if_scores_normal)})', density=True)\n",
    "ax.hist(if_scores_anomaly, bins=40, alpha=0.7, color='#D7191C',\n",
    "        label=f'Anomaly (n={len(if_scores_anomaly)})', density=True)\n",
    "ax.set_xlabel('Isolation Forest Anomaly Score (lower = more anomalous)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Isolation Forest Score Distribution: Normal vs. Anomaly')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../model/artifacts/nb_score_dist.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Normal mean score:  {if_scores_normal.mean():.4f} ± {if_scores_normal.std():.4f}')\n",
    "print(f'Anomaly mean score: {if_scores_anomaly.mean():.4f} ± {if_scores_anomaly.std():.4f}')\n",
    "print(f'Separation (Cohen d): {abs(if_scores_normal.mean() - if_scores_anomaly.mean()) / np.sqrt((if_scores_normal.std()**2 + if_scores_anomaly.std()**2)/2):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Z-score Threshold Sensitivity\n",
    "\n",
    "The Z-score detector has one tunable parameter: threshold. Let's find the optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'isolation_forest': iforest, 'lof': lof, 'scaler': scaler}\n",
    "\n",
    "thresholds = np.arange(1.5, 5.1, 0.25)\n",
    "f1_scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    pred = ensemble_predict(models, X_test, z_threshold=t)\n",
    "    f1_scores.append(f1_score(y_test, pred, zero_division=0))\n",
    "\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_t = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(thresholds, f1_scores, 'o-', color='#2C7BB6', linewidth=2)\n",
    "ax.axvline(best_t, color='#D7191C', linestyle='--', label=f'Best: threshold={best_t} (F1={best_f1:.3f})')\n",
    "ax.set_xlabel('Z-score Threshold')\n",
    "ax.set_ylabel('Ensemble F1 Score')\n",
    "ax.set_title('Ensemble F1 vs Z-score Threshold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../model/artifacts/nb_threshold_sweep.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Best Z-score threshold: {best_t} → F1 = {best_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Model — Train and Verify\n",
    "\n",
    "Run the full training pipeline and verify the saved model loads correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['python', '../model/train.py'], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.returncode != 0:\n",
    "    print('STDERR:', result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the saved model works\n",
    "from app.predictor import AnomalyPredictor\n",
    "\n",
    "pred = AnomalyPredictor(model_path='../model/artifacts/ensemble_model.joblib')\n",
    "print('Model loaded:', pred.is_loaded)\n",
    "\n",
    "# Test normal observation\n",
    "normal_result = pred.predict([0.1, 0.2, -0.1, 0.3, 0.0, 0.15, -0.05, 0.25])\n",
    "print(f'\\nNormal observation:')\n",
    "print(f'  is_anomaly: {normal_result[\"is_anomaly\"]}')\n",
    "print(f'  confidence: {normal_result[\"confidence\"]}')\n",
    "print(f'  votes: {normal_result[\"votes\"]}')\n",
    "\n",
    "# Test anomalous observation\n",
    "anomaly_result = pred.predict([8.5, -7.2, 9.1, -8.8, 7.6, -9.3, 8.2, -7.5])\n",
    "print(f'\\nAnomalous observation:')\n",
    "print(f'  is_anomaly: {anomaly_result[\"is_anomaly\"]}')\n",
    "print(f'  confidence: {anomaly_result[\"confidence\"]}')\n",
    "print(f'  votes: {anomaly_result[\"votes\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.11.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
